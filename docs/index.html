<script src="http://www.google.com/jsapi" type="text/javascript"></script> 
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
    body {
        font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif; 
        font-weight:300;
        font-size:18px;
        margin-left: auto;
        margin-right: auto;
        width: 1100px;
    }
    
    h1 {
        font-size:32px;
        font-weight:300;
    }
    
    .disclaimerbox {
        background-color: #eee;     
        border: 1px solid #eeeeee;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
        padding: 20px;
    }

    video.header-vid {
        height: 140px;
        border: 1px solid black;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
    }
    
    img.header-img {
        height: 140px;
        border: 1px solid black;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
    }
    
    img.rounded {
        border: 1px solid #eeeeee;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
    }
    
    a:link,a:visited
    {
        color: #1367a7;
        text-decoration: none;
    }
    a:hover {
        color: #208799;
    }
    
    td.dl-link {
        height: 160px;
        text-align: center;
        font-size: 22px;
    }
    
    .layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
        box-shadow:
        0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
        5px 5px 0 0px #fff, /* The second layer */
        5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
        10px 10px 0 0px #fff, /* The third layer */
        10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
        15px 15px 0 0px #fff, /* The fourth layer */
        15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
        20px 20px 0 0px #fff, /* The fifth layer */
        20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
        25px 25px 0 0px #fff, /* The fifth layer */
        25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
        margin-left: 10px;
        margin-right: 45px;
    }

    .paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
        box-shadow:
        0px 0px 1px 1px rgba(0,0,0,0.35); /* The top layer shadow */

        margin-left: 10px;
        margin-right: 45px;
    }


    .layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
        box-shadow:
        0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
        5px 5px 0 0px #fff, /* The second layer */
        5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
        10px 10px 0 0px #fff, /* The third layer */
        10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
        margin-top: 5px;
        margin-left: 10px;
        margin-right: 30px;
        margin-bottom: 5px;
    }
    
    .vert-cent {
        position: relative;
        top: 50%;
        transform: translateY(-50%);
    }
    
    hr
    {
        border: 0;
        height: 1px;
        background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
    }
</style>

<html>
<head>
    <title>Comparing Correspondences</title>
    <meta property="og:image" content="resources/teaser.jpg"/> <!-- Facebook automatically scrapes this. Go to https://developers.facebook.com/tools/debug/ if you update and want to force Facebook to rescrape. -->
    <meta property="og:title" content="Correspondence-wise Losses" />
    <meta property="og:description" content="Comparing correspondences rather than pixels." />

    <!-- Get from Google Analytics -->
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src=""></script> 
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'UA-81285507-1');
    </script>
</head>

<body>
    <br>
    <center>
        <span style="font-size:36px">Comparing Correspondences: Video Prediction with <br> Correspondence-wise Losses</span>
        <table align=center width=600px>
            <table align=center width=600px>
                <tr>
                    <td align=center width=100px>
                        <center>
                            <span style="font-size:24px"><a href="https://dangeng.github.io" target="_blank">Daniel Geng</a></span>
                        </center>
                    </td>
                    <td align=center width=100px>
                        <center>
                            <span style="font-size:24px"><a href="https://johnmaxh.github.io/" target="_blank">Max Hamilton</a></span>
                        </center>
                    </td>
                    <td align=center width=100px>
                        <center>
                            <span style="font-size:24px"><a href="http://andrewowens.com/" target="_blank">Andrew Owens</a></span>
                        </center>
                    </td>
                </tr>
            </table>
            <table align=center width=250px>
                <tr>
                    <td align=center width=120px>
                        <center>
                            <span style="font-size:24px"><a target="_blank" href='https://arxiv.org/abs/2104.09498'>[Paper]</a></span>
                        </center>
                    </td>
                    <td align=center width=120px>
                        <center>
                            <span style="font-size:24px"><a target="_blank" href='https://github.com/dangeng/CorrWiseLosses'>[GitHub]</a></span><br>
                        </center>
                    </td>
                </tr>
            </table>
        </table>
    </center>

    <center>
        <br>
        <table align=center width=850px>
            <tr>
                <td width=260px>
                    <center>
                        <video controls autoplay loop muted width='800px'>
                          <source src="./resources/teaser.mp4" type="video/mp4"/>
                        </video>
                    </center>
                </td>
            </tr>
        </table>
        <table align=center width=800px>
            <center>
                <tr>
                    <td style='text-align: center'>
                      Losses typically compare pixels to pixels or patches to patches by absolute location. Instead, what would happen if we compare patches or pixels to <i>corresponding </i> patches or pixels? We propose <b>correspondence-wise</b> losses that do just this, and compare them against traditional pixel-wise and patch-wise losses.
                    </td>
                </tr>
            </center>
        </table>
    </center>
    <br>

    <hr>

    <table align=center width=850px>
        <center><h1>Abstract</h1></center>
        <tr>
            <td>
              <p>Image prediction methods often struggle on tasks that require changing the positions of objects, such as video prediction, producing blurry images that average over the many positions that objects might occupy. In this paper, we propose a simple change to existing image similarity metrics that makes them more robust to positional errors: we match the images using optical flow, then measure the visual similarity of <b>corresponding</b> pixels. This change leads to crisper and more perceptually accurate predictions, and does not require modifications to the image prediction network. We apply our method to a variety of video prediction tasks, where it obtains strong performance with simple network architectures, and to the closely related task of video interpolation.</p>
            </td>
        </tr>
    </table>
    <br>

    <hr>
    <center><h1>Toy Experiment</h1></center>

    <table align=center width=850px>
      <tr>
        <td>
          <p>As a way to understand correspondence-wise losses in a simple scenario, we create a toy dataset by starting with a static background and then sampling a car's horizontal position uniformally about the center of the image. In this way we can simulate <i>positional uncertainty</i>. We can then ask for networks trained under various losses, <b>what is the optimal prediction under this uncertainty?</b></p>
        </td>
      </tr>
    </table>
    <br>

    <div style="margin: auto; width: 50%; padding-left: 40px;">
      <img name="viz_toy" src="./resources/viz/toy/sample.png" style="margin-bottom: 20px; border: 1px solid">
      <table border="1px solid black" style="border-collapse: collapse">
        <tr>
          <td class="btn_toy" height="100px" onmouseover="document.viz_toy.src='./resources/viz/toy/sample.png';[].forEach.call(document.getElementsByClassName('btn_toy'),(el)=&gt;el.style.backgroundColor='white');this.style.backgroundColor='rgb(204,255,204)';" style="cursor:pointer; text-align: center; background-color: rgb(204,255,204);" width="100px">Sample</td>
          <td class="btn_toy" height="100px" onmouseover="document.viz_toy.src='./resources/viz/toy/mse.png';[].forEach.call(document.getElementsByClassName('btn_toy'),(el)=&gt;el.style.backgroundColor='white');this.style.backgroundColor='rgb(204,255,204)';" style="cursor:pointer; text-align: center;" width="100px">MSE</td>
          <td class="btn_toy" height="100px" onmouseover="document.viz_toy.src='./resources/viz/toy/l1.png';[].forEach.call(document.getElementsByClassName('btn_toy'),(el)=&gt;el.style.backgroundColor='white');this.style.backgroundColor='rgb(204,255,204)';" style="cursor:pointer; text-align: center;" width="100px">L1</td>
          <td class="btn_toy" height="100px" onmouseover="document.viz_toy.src='./resources/viz/toy/l1p.png';[].forEach.call(document.getElementsByClassName('btn_toy'),(el)=&gt;el.style.backgroundColor='white');this.style.backgroundColor='rgb(204,255,204)';" style="cursor:pointer; text-align: center;" width="100px">L1 + Perceptual</td>
          <td class="btn_toy" height="100px" onmouseover="document.viz_toy.src='./resources/viz/toy/l1_corr.png';[].forEach.call(document.getElementsByClassName('btn_toy'),(el)=&gt;el.style.backgroundColor='white');this.style.backgroundColor='rgb(204,255,204)';" style="cursor:pointer; text-align: center;" width="100px">Corr-wise L1</td>
        </tr>
      </table>
    </div>
    <br>

    <table align=center width=850px>
      <tr>
        <td>
          <p>Under the L1 and the MSE loss a network produces poor images (analytically, these are the median and the mean respectively). Perhaps more surprisingly, the perceptual loss also performs badly. A correspondence-wise loss, on the other hand, is able to faithfully reproduce the car.</p>
        </td>
      </tr>
    </table>
    <br>

    <hr>
    

    <center><h1>Ablations</h1></center>

    <table align=center width=850px>
      <tr>
        <td>
          <p>We train video predictions using both pixel-wise and correspondence-wise losses. All else being equal, we find that training with a correspondence-wise loss produces higher quality images, especially when there is large amounts of spatial uncertainty.</p>
          <p>Below is an example in which there is a sudden camera movement in the context frames. This causes a poor L1 prediction, which a corr-wise L1 trained network improves upon: </p>
        </td>
      </tr>
    </table>
    <br>





    <div style="margin: auto; width: 50%; padding-left: 40px;">
      <img name="viz_1" src="./resources/viz/1/gen_pix.png" style="margin-bottom: 20px; border: 1px solid">
      <table border="1px solid black" style="border-collapse: collapse">
        <tr>
          <td class="btn_1" height="100px" onmouseover="document.viz_1.src='./resources/viz/1/ctx_1.png';[].forEach.call(document.getElementsByClassName('btn_1'),(el)=&gt;el.style.backgroundColor='white');this.style.backgroundColor='rgb(204,255,204)';" style="cursor:pointer; text-align: center;" width="100px">Context 1</td>
          <td class="btn_1" height="100px" onmouseover="document.viz_1.src='./resources/viz/1/ctx_2.png';[].forEach.call(document.getElementsByClassName('btn_1'),(el)=&gt;el.style.backgroundColor='white');this.style.backgroundColor='rgb(204,255,204)';" style="cursor:pointer; text-align: center;" width="100px">Context 2</td>
          <td class="btn_1" height="100px" onmouseover="document.viz_1.src='./resources/viz/1/ctx_3.png';[].forEach.call(document.getElementsByClassName('btn_1'),(el)=&gt;el.style.backgroundColor='white');this.style.backgroundColor='rgb(204,255,204)';" style="cursor:pointer; text-align: center;" width="100px">Context 3</td>
          <td class="btn_1" height="100px" onmouseover="document.viz_1.src='./resources/viz/1/gen_pix.png';[].forEach.call(document.getElementsByClassName('btn_1'),(el)=&gt;el.style.backgroundColor='white');this.style.backgroundColor='rgb(204,255,204)';" style="cursor:pointer; text-align: center;background-color: rgb(204,255,204);" width="100px">Pixel-wise L1 Prediciton</td>
          <td class="btn_1" height="100px" onmouseover="document.viz_1.src='./resources/viz/1/gen_corr.png';[].forEach.call(document.getElementsByClassName('btn_1'),(el)=&gt;el.style.backgroundColor='white');this.style.backgroundColor='rgb(204,255,204)';" style="cursor:pointer; text-align: center;" width="100px">Corr-wise L1 Prediciton</td>
        </tr>
      </table>
    </div>
    <br>
    <br>


    <table align=center width=850px>
      <tr>
        <td>
          <p>A perceptual + L1 trained network does better, but still has artifacts. Turning the perceptual + L1 loss into a correspondence-wise loss produces a much more appealing prediction:</p>
        </td>
      </tr>
    </table>
    <br>



    <div style="margin: auto; width: 50%; padding-left: 40px;">
      <img name="viz_2" src="./resources/viz/2/gen_pix.png" style="margin-bottom: 20px; border: 1px solid">
      <table border="1px solid black" style="border-collapse: collapse">
        <tr>
          <td class="btn_2" height="100px" onmouseover="document.viz_2.src='./resources/viz/2/ctx_1.png';[].forEach.call(document.getElementsByClassName('btn_2'),(el)=&gt;el.style.backgroundColor='white');this.style.backgroundColor='rgb(204,255,204)';" style="cursor:pointer; text-align: center;" width="100px">Context 1</td>
          <td class="btn_2" height="100px" onmouseover="document.viz_2.src='./resources/viz/2/ctx_2.png';[].forEach.call(document.getElementsByClassName('btn_2'),(el)=&gt;el.style.backgroundColor='white');this.style.backgroundColor='rgb(204,255,204)';" style="cursor:pointer; text-align: center;" width="100px">Context 2</td>
          <td class="btn_2" height="100px" onmouseover="document.viz_2.src='./resources/viz/2/ctx_3.png';[].forEach.call(document.getElementsByClassName('btn_2'),(el)=&gt;el.style.backgroundColor='white');this.style.backgroundColor='rgb(204,255,204)';" style="cursor:pointer; text-align: center;" width="100px">Context 3</td>
          <td class="btn_2" height="100px" onmouseover="document.viz_2.src='./resources/viz/2/gen_pix.png';[].forEach.call(document.getElementsByClassName('btn_2'),(el)=&gt;el.style.backgroundColor='white');this.style.backgroundColor='rgb(204,255,204)';" style="cursor:pointer; text-align: center;background-color: rgb(204,255,204);" width="100px">Pixel-wise L1 + Perceptual Prediciton</td>
          <td class="btn_2" height="100px" onmouseover="document.viz_2.src='./resources/viz/2/gen_corr.png';[].forEach.call(document.getElementsByClassName('btn_2'),(el)=&gt;el.style.backgroundColor='white');this.style.backgroundColor='rgb(204,255,204)';" style="cursor:pointer; text-align: center;" width="100px">Corr-wise L1 + Perceptual Prediciton</td>
        </tr>
      </table>
    </div>
    <br>




    <hr>
    <table align=center width=850px>
      <center><h1>Training Visualization</h1></center>
      <tr>
        <td width=128px>
          <center>
            <video controls autoplay loop muted>
              <source src="./resources/training.mp4" type="video/mp4"/>
            </video>
          </center>
        </td>
      </tr>
    </table>
    <br>
    <table align=center width=850px>
      <tr>
        <td>
          <center>
            <div style='width:700px;'>
              <p>A visualization of training with a correspondence-wise loss from the toy experiment. Notice how content is generated first and then the position of objects is refined.</p>
            </div>
          </center>
        </td>
      </tr>
    </table>
    <br>





    <hr>
    <table align=center width=450px>
        <center><h1>Paper and Supplementary Material</h1></center>
        <center><p>For more details and experiments check out our paper:</p></center>
        <tr>
            <td><a target="_blank" href='https://arxiv.org/abs/2104.09498'><img class="layered-paper-big" style="height:175px" src="./resources/paper.png"/></a></td>
            <td><span style="font-size:14pt">Geng, Hamilton, Owens.<br>
                Comparing Correspondences.<br>
                CVPR 2022.<br>
                (hosted on <a target="_blank" href="https://arxiv.org/abs/2104.09498">ArXiv</a>)<br>
                </span>
            </td>
        </tr>
    </table>
    <br>

    <table align=center width=600px>
        <tr>
            <td><span style="font-size:14pt"><center>
                <a href="./resources/bibtex.txt" target="_blank">[Bibtex]</a>
            </center></td>
        </tr>
    </table>
    <br>

    <hr>
    <br>

    <table align=center width=900px>
        <tr>
            <td width=400px>
                <center>
                    This <a href="https://github.com/richzhang/webpage-template">template</a> was originally made by <a href="http://web.mit.edu/phillipi/">Phillip Isola</a> and <a href="http://richzhang.github.io/">Richard Zhang</a>.
                </center>
            </td>
        </tr>
    </table>

<br>
</body>
</html>






